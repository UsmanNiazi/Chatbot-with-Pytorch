{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "chatbot.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yLaDH36wKqkF"
      },
      "source": [
        "# Building a Chatbot with Pytorch\n",
        "---\n",
        "Hello World. Ever thought how Alexa, Siri or Google voice assistant worked? Think no more. We will be building an entire chatbot that can actually understand what are you trying to say. You do need a basic knowledge of Python, Pytorch and a little bit of other things. Lets get Started. Keep in mind that this is a very basic Neural Network thatr will get you started with NLP .\n",
        "\n",
        "Before Proceeding, Here is a list of Requirements for the tutorial. There are tons of Tutorials available online where you can learn these things."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "25-AZz20xuNk"
      },
      "source": [
        "\n",
        "## Requirements:\n",
        "- Python 3\n",
        "- Dictionaries & Lists\n",
        "- Numpy\n",
        "- Pandas\n",
        "- Pytorch\n",
        "- Natural Language Processing (Bag of Words)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pz2iL5UQyF40"
      },
      "source": [
        "## Software Used:\n",
        "-\tGoogle Colab (You can use any other software that supports Jupyter Notebooks)\n",
        "-\tGoogle Drive ( You can use your local machine or github as well)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UUOkxVXJyDQz"
      },
      "source": [
        "\n",
        "### Read this if you are using google collab with drive:\n",
        "You need to do little tweaks if you want to access files or datasets that are stored in your drive. \n",
        "1. you need to install a library called PyDrive (installation method Is in the notebook)\n",
        "2. Paste your dataset or file in the colab notebooks folder in drive. \n",
        "3. right click on it and click on get link\n",
        "4. paste the link anywhere (preferrabally in notepad) & extract the file ID\n",
        "5. the file ID can be obtained from the link. The file ID is alphanumeric characters between `/d/` and `/view?usp=sharing`\n",
        "6. Paste File ID here  \n",
        "7. You can replace the intents.json filename to whatever you want.\n",
        "\n",
        "\n",
        "```python\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "```\n",
        "```python\n",
        "downloaded = drive.CreateFile({'id':\"File ID here\"})   # replace the id with id of file you want to access\n",
        "downloaded.GetContentFile('intents.json')        # replace the file name with your file\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PyRLSl-QyWpw"
      },
      "source": [
        "\n",
        "## Introduction\n",
        "---\n",
        "___What exactly is a chatbot?___\n",
        "\n",
        "    A chatbot is an artificial intelligence (AI) software that can simulate a conversation (or a chat) with a user in natural language through messaging applications, websites, mobile apps or through the telephone.\n",
        "___Why are chatbots important?___ \n",
        "\n",
        " A chatbot is often described as one of the most advanced and promising expressions of interaction between humans and machines. However, from a technological point of view, a chatbot only represents the natural evolution of a Question Answering system leveraging Natural Language Processing (NLP). Formulating responses to questions in natural language is one of the most typical Examples of Natural Language Processing applied in various enterprises’ end-use applications.\n",
        "A chatbot usually considered as a first step towards your NLP Career. It opens endless opportunity of research and commercial projects which are not only fun to do but also not so difficult to implement\n",
        "\n",
        "\n",
        "Everything is explained in the Notebook \n",
        "\n",
        "We will make a custom function for everything that is used so that we can reuse the function in any other project later. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qTvkr73KynZr"
      },
      "source": [
        "\n",
        "## Getting Ready\n",
        "---\n",
        "As you might be familiar with the fact that computers are good at performing calculations at numbers, not some random form of data. As there is a famous saying in ML that “Garbage In, Garbage Out”. The quality of your data will define how good or bad your Machine Learning Model will perform. So we have to clean or pre-process our data before we move on to build our model. \n",
        "\n",
        "    Preprocessing in NLP is quite different from traditional Machine Learning or Deep Learning. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EHQZmMImynfM"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H5ZOgXz4ynw_"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YJ5lKI1Iynuc"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-nQr2QeSynsS"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C_-vadS0ynp3"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MRMHYbiOynnv"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pPQabiMoynle"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uU25r58NynjL"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qse4rXu-yndk"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iAbK_E0wx9hO"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ohgo7RfCxucM"
      },
      "source": [
        "### ___Importing Relevant Libraries___\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "### Note: \n",
        "- If You do no have them installed, Run **!pip install \"Library Name here\"**. For Example, if I want to install **nltk**, I will write !pip install nltk\n",
        "- also if this is your first time running nltk. you might have to run nltk.download('punkt') or nltk.download(). I have written the command but commented it out. incase you need to use it, just type it or uncomment it.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UX-IHmDnKzdp"
      },
      "source": [
        "import numpy as np\n",
        "import random\n",
        "import json\n",
        "import nltk\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IkfqimbJzkra"
      },
      "source": [
        "\n",
        "### Creating Custom Functions:\n",
        "We will create custom Functions so that it is easy for us to implement afterwards."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KmFTdWXBNKhY"
      },
      "source": [
        "def tokenize(sentence):\n",
        "    return nltk.word_tokenize(sentence)\n",
        "\n",
        "def stem(word):\n",
        "    return stemmer.stem(word.lower())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A3OXxl0gzs60"
      },
      "source": [
        "\n",
        "\n",
        "Nltk or natural language took kit is a really useful library that contains important classes that will be useful in any of your NLP task. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VGJT8o23KeLp"
      },
      "source": [
        "\n",
        "### Stemming\n",
        "\n",
        "\n",
        "If we have 3 words like “walk”, “walked”, “walking”, these might seem different words but they generally have the same meaning and also have the same base form; “walk”. So, in order for our model to understand all different form of the same words we need to train our model with that form. This is called Stemming. There are different methods that we can use for stemming. Here we will use Porter Stemmer model form our NLTK Library. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bj7CewZ2Jg1x"
      },
      "source": [
        "from nltk.stem.porter import PorterStemmer\n",
        "stemmer = PorterStemmer()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zgl_t__tz_F9"
      },
      "source": [
        "\n",
        "### Bag of Words:\n",
        "\t\n",
        "We will be splitting each word in the sentences and adding it to an array.\n",
        "We will be using bag of words. Which will initially be a list of zeros with the size equal to the length of the all words array.\n",
        " \n",
        "If we have a array of ` sentences = [\"hello\", \"how\", \"are\", \"you\"]` \n",
        "and an array of total ` words = [\"hi\", \"hello\", \"I\", \"you\", \"bye\", \"thank\", \"cool\"]` then its bag of words array will be `bog  = [  0 ,    1 ,    0 ,   1 ,    0 ,    0 ,      0]`. \n",
        "\n",
        "We will loop over the each word in the all words array and the bog array corresponding to each word. If a word from the sentence is found in the all words array, 1 will be replaced at that index/position in bog array.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ddQDX1wQKYMQ"
      },
      "source": [
        "\n",
        "def bag_of_words(tokenized_sentence, words):\n",
        "    \"\"\"\n",
        "    return bag of words array:\n",
        "    1 for each known word that exists in the sentence, 0 otherwise\n",
        "    example:\n",
        "    sentence = [\"hello\", \"how\", \"are\", \"you\"]\n",
        "    words = [\"hi\", \"hello\", \"I\", \"you\", \"bye\", \"thank\", \"cool\"]\n",
        "    bog   = [  0 ,    1 ,    0 ,   1 ,    0 ,    0 ,      0]\n",
        "    \"\"\"\n",
        "    # stem each word\n",
        "    sentence_words = [stem(word) for word in tokenized_sentence]\n",
        "    # initialize bag with 0 for each word\n",
        "    bag = np.zeros(len(words), dtype=np.float32)\n",
        "    for idx, w in enumerate(words):\n",
        "        if w in sentence_words: \n",
        "            bag[idx] = 1\n",
        "\n",
        "    return bag"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YFeclhqH0ISR"
      },
      "source": [
        "\n",
        "During the the process , we will also use ***nltk.word_tokenize()*** which will convert a single sentence string into a list of word. E.g if you pass `\"hello how are you\"`, it will return `[\"hello\", \"how\", \"are\", \"you\"]`. \n",
        "\n",
        "**Note:**\n",
        "    we will pass lower case words to the stemmer so that words like Good and good  (capitalized)  won’t be labelled as different words."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xQIlqWdLNn_g"
      },
      "source": [
        "\n",
        "### Loading the Data & Cleaning it\n",
        "\n",
        "We will be using a data set called ***intents.json*** which has the following structure. We will be cleaning this data according to our need by using the functions that we created earlier.\n",
        "\n",
        "\n",
        "\n",
        "```json\n",
        "{\n",
        "  \"intents\": [\n",
        "    {\n",
        "      \"tag\": \"greeting\",\n",
        "      \"patterns\": [\n",
        "        \"Hi\",\n",
        "        \"Hey\",\n",
        "        \"How are you\",\n",
        "        \"Is anyone there?\",\n",
        "        \"Hello\",\n",
        "        \"Good day\"\n",
        "      ],\n",
        "      \"responses\": [\n",
        "        \"Hey :-)\",\n",
        "        \"Hello, thanks for visiting\",\n",
        "        \"Hi there, what can I do for you?\",\n",
        "        \"Hi there, how can I help?\"\n",
        "      ]\n",
        "    },\n",
        "    {\n",
        "      \"tag\": \"goodbye\",\n",
        "      \"patterns\": [\"Bye\", \"See you later\", \"Goodbye\"],\n",
        "      \"responses\": [\n",
        "        \"See you later, thanks for visiting\",\n",
        "        \"Have a nice day\",\n",
        "        \"Bye! Come back again soon.\"\n",
        "      ]\n",
        "    },\n",
        "    {\n",
        "      \"tag\": \"thanks\",\n",
        "      \"patterns\": [\"Thanks\", \"Thank you\", \"That's helpful\", \"Thank's a lot!\"],\n",
        "      \"responses\": [\"Happy to help!\", \"Any time!\", \"My pleasure\"]\n",
        "    },\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pYZlZB6Q0iqz"
      },
      "source": [
        "\n",
        "\n",
        "Seems familiar? If you noticed , this looks similar to nested dictionary in python. That’s how **JSON** is formatted. \n",
        "Now we will simply load the json file using ***json.load()*** function.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dyslTCEcNm0X"
      },
      "source": [
        "with open('intents.json', 'r') as f:\n",
        "    intents = json.load(f)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oG34WNmv0mSI"
      },
      "source": [
        "\n",
        "In order to get the right information, we will be unpacking it with the following code. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-2p39Ghz0pYl"
      },
      "source": [
        "all_words = []\n",
        "tags = []\n",
        "xy = []\n",
        "# loop through each sentence in our intents patterns\n",
        "for intent in intents['intents']:\n",
        "    tag = intent['tag']\n",
        "    # add to tag list\n",
        "    tags.append(tag)\n",
        "    for pattern in intent['patterns']:\n",
        "        # tokenize each word in the sentence\n",
        "        w = tokenize(pattern)\n",
        "        # add to our words list\n",
        "        all_words.extend(w)\n",
        "        # add to xy pair\n",
        "        xy.append((w, tag))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F4LQ1UgC0vPS"
      },
      "source": [
        "\n",
        "This will separate all the tags & words into their separate lists\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3EmUzJjD0xmT"
      },
      "source": [
        "\n",
        "### Cleaning & Preparing the data using our custom functions\n",
        "\n",
        "We will be cleaning the data by implementing the functions we created in our previous cells."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q0DOKFv5OP_Y",
        "outputId": "ba8a35a2-adf2-4725-8854-3846af2eb7b0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "# stem and lower each word\n",
        "ignore_words = ['?', '.', '!']\n",
        "all_words = [stem(w) for w in all_words if w not in ignore_words]\n",
        "# remove duplicates and sort\n",
        "all_words = sorted(set(all_words))\n",
        "tags = sorted(set(tags))\n",
        "\n",
        "print(len(xy), \"patterns\")\n",
        "print(len(tags), \"tags:\", tags)\n",
        "print(len(all_words), \"unique stemmed words:\", all_words)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "26 patterns\n",
            "7 tags: ['delivery', 'funny', 'goodbye', 'greeting', 'items', 'payments', 'thanks']\n",
            "54 unique stemmed words: [\"'s\", 'a', 'accept', 'anyon', 'are', 'bye', 'can', 'card', 'cash', 'credit', 'day', 'deliveri', 'do', 'doe', 'funni', 'get', 'good', 'goodby', 'have', 'hello', 'help', 'hey', 'hi', 'how', 'i', 'is', 'item', 'joke', 'kind', 'know', 'later', 'long', 'lot', 'mastercard', 'me', 'my', 'of', 'onli', 'pay', 'paypal', 'see', 'sell', 'ship', 'someth', 'take', 'tell', 'thank', 'that', 'there', 'what', 'when', 'which', 'with', 'you']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yD89rBDx1PSh"
      },
      "source": [
        "\n",
        "### Creating Training Data: \n",
        "We will transform the data into a format that our PyTorch Model can Easily Understand\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7s-rOPCaO355"
      },
      "source": [
        "# create training data\n",
        "X_train = []\n",
        "y_train = []\n",
        "for (pattern_sentence, tag) in xy:\n",
        "    # X: bag of words for each pattern_sentence\n",
        "    bag = bag_of_words(pattern_sentence, all_words)\n",
        "    X_train.append(bag)\n",
        "    # y: PyTorch CrossEntropyLoss needs only class labels, not one-hot\n",
        "    label = tags.index(tag)\n",
        "    y_train.append(label)\n",
        "\n",
        "X_train = np.array(X_train)\n",
        "y_train = np.array(y_train)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F_m272pI1S7x"
      },
      "source": [
        "\n",
        "    `One hot encoding Is the process of splitting multiclass or multi valued data column to separate columns and labelling the cell 1 in the row where it exists. (we won’t use it so don’t worry about it)`\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PZrtTYkV1dKI"
      },
      "source": [
        "\n",
        "## PyTorch Model\n",
        "---\n",
        "Here we will be making a class to implement our custom neural network. It will be a feed forward neural Network which will have 3 Linear Layers and we will be using activation function “ReLU” . \n",
        "\n",
        "    Note: \n",
        "    We have used the super() function to inherit the properties of its parent class. \n",
        "    This is an Object Oriented Programming (OOP) concept.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dp6tJu-01mRM"
      },
      "source": [
        "\n",
        "### Feed Forward Neural Network\n",
        "\n",
        "`A feedforward neural network is an artificial neural network wherein connections between the nodes do not form a cycle. As such, it is different from its descendant: recurrent neural networks.`\n",
        "\n",
        "\n",
        "The feedforward neural network was the first and simplest type of artificial neural network devised In this network, the information moves in only one direction—forward—from the input nodes, through the hidden nodes (if any) and to the output nodes. There are no cycles or loops in the network [1] \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "18x2TO5n1pAg"
      },
      "source": [
        "\n",
        "### Activation Function:\n",
        "`\n",
        "An activation function is a function used in artificial neural networks which outputs a small value for small inputs, and a larger value if its inputs exceed a threshold. If the inputs are large enough, the activation function \"fires\", otherwise it does nothing. In other words, an activation function is like a gate that checks that an incoming value is greater than a critical number. [2]`\n",
        "\n",
        "\n",
        "Activation functions are useful because they add non-linearities into neural networks, allowing the neural networks to learn powerful operations. If the activation functions were to be removed from a feedforward neural network, the entire network could be re-factored to a simple linear operation or matrix transformation on its input, and it would no longer be capable of performing complex tasks such as image recognition."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K7LUU9Fh1ulb"
      },
      "source": [
        "\n",
        "### ReLU Function:\n",
        "There are a number of widely used activation functions in deep learning today. One of the simplest is the rectified linear unit, or ReLU function, which is a piece wise linear function that outputs zero if its input is negative, and directly outputs the input otherwise:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TXkhfnhk1_cL"
      },
      "source": [
        "\n",
        "### ReLU Function Derivative:\n",
        "\n",
        "It is also instructive to calculate the gradient of the ReLU function, which is mathematically undefined at x = 0 but which is still extremely useful in neural networks.\n",
        "\n",
        "\n",
        "The derivative of the ReLU function. In practice the derivative at x = 0 can be set to either 0 or 1. \n",
        "The zero derivative for negative x can give rise to problems when training a neural network, since a neuron can become 'trapped' in the zero region and backpropagation will never change its weights. [2] "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FV2Xx8dM2H_t"
      },
      "source": [
        "\n",
        "## Creating our Model\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nzu2XD-5QhK1"
      },
      "source": [
        "class NeuralNet(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_classes):\n",
        "        super(NeuralNet, self).__init__()\n",
        "        self.l1 = nn.Linear(input_size, hidden_size) \n",
        "        self.l2 = nn.Linear(hidden_size, hidden_size) \n",
        "        self.l3 = nn.Linear(hidden_size, num_classes)\n",
        "        self.relu = nn.ReLU()\n",
        "    \n",
        "    def forward(self, x):\n",
        "        out = self.l1(x)\n",
        "        out = self.relu(out)\n",
        "        out = self.l2(out)\n",
        "        out = self.relu(out)\n",
        "        out = self.l3(out)\n",
        "        # no activation and no softmax at the end\n",
        "        return out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0_l3tcJ02PEW"
      },
      "source": [
        "\n",
        "Here we have inherited a class from NN.Module because we will be customizing the model & its layers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "76wT8MFt2TA7"
      },
      "source": [
        "\n",
        "###\tAssigning the Dataset to the Model:\n",
        "We will use some Magic functions, write our class.\n",
        "\n",
        "You can read online about `__getitem__` and `__getitem__` magic funtions. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Btm83RGv2Z2s"
      },
      "source": [
        "class ChatDataset(Dataset):\n",
        "\n",
        "    def __init__(self):\n",
        "        self.n_samples = len(X_train)\n",
        "        self.x_data = X_train\n",
        "        self.y_data = y_train\n",
        "\n",
        "    # support indexing such that dataset[i] can be used to get i-th sample\n",
        "    def __getitem__(self, index):\n",
        "        return self.x_data[index], self.y_data[index]\n",
        "\n",
        "    # we can call len(dataset) to return the size\n",
        "    def __len__(self):\n",
        "        return self.n_samples"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vB20cElA2bKY"
      },
      "source": [
        "\n",
        "###\tHyper Parameters:\n",
        "Every Neural network has a set of hyper parameters that need to be set before use. \n",
        "\n",
        "Before Instantiating our Neural Net Class or Model that we wrote earlier, we will first define some hyper parameters which can be changed accordingly."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ZWPYYnTO7Cb",
        "outputId": "d2f1f117-1be2-4c8b-f855-bd49d2f1710c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 32
        }
      },
      "source": [
        "\n",
        "# Hyper-parameters \n",
        "num_epochs = 1000\n",
        "batch_size = 8\n",
        "learning_rate = 0.001\n",
        "input_size = len(X_train[0])\n",
        "hidden_size = 8\n",
        "output_size = len(tags)\n",
        "print(input_size, output_size)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "54 7\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qOVWmO6H2iFI"
      },
      "source": [
        "\n",
        "###\tLoss and optimizer: \n",
        "We will now Instantiate the model, loss and optimizer functions.\n",
        "\n",
        "    Loss Function: Cross Entropy \n",
        "    Optimizer: Adam Optimizer\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4X5AN0ikPCmR"
      },
      "source": [
        "dataset = ChatDataset()\n",
        "train_loader = DataLoader(dataset=dataset,\n",
        "                          batch_size=batch_size,\n",
        "                          shuffle=True,\n",
        "                          num_workers=0)\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "model = NeuralNet(input_size, hidden_size, output_size).to(device)\n",
        "\n",
        "# Loss and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TjRZC0f52riv"
      },
      "source": [
        "\n",
        "## Training the Model\n",
        "---\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6vaFH57TPLe2",
        "outputId": "b768f2ba-35f5-4a8f-e9f9-b5842c67a0f3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        }
      },
      "source": [
        "\n",
        "# Train the model\n",
        "for epoch in range(num_epochs):\n",
        "    for (words, labels) in train_loader:\n",
        "        words = words.to(device)\n",
        "        labels = labels.to(dtype=torch.long).to(device)\n",
        "        \n",
        "        # Forward pass\n",
        "        outputs = model(words)\n",
        "        # if y would be one-hot, we must apply\n",
        "        # labels = torch.max(labels, 1)[1]\n",
        "        loss = criterion(outputs, labels)\n",
        "        \n",
        "        # Backward and optimize\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "    if (epoch+1) % 100 == 0:\n",
        "        print (f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
        "\n",
        "\n",
        "print(f'final loss: {loss.item():.4f}')\n",
        "\n",
        "data = {\n",
        "\"model_state\": model.state_dict(),\n",
        "\"input_size\": input_size,\n",
        "\"hidden_size\": hidden_size,\n",
        "\"output_size\": output_size,\n",
        "\"all_words\": all_words,\n",
        "\"tags\": tags\n",
        "}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch [100/1000], Loss: 1.1189\n",
            "Epoch [200/1000], Loss: 0.0644\n",
            "Epoch [300/1000], Loss: 0.0062\n",
            "Epoch [400/1000], Loss: 0.0033\n",
            "Epoch [500/1000], Loss: 0.0095\n",
            "Epoch [600/1000], Loss: 0.0006\n",
            "Epoch [700/1000], Loss: 0.0017\n",
            "Epoch [800/1000], Loss: 0.0020\n",
            "Epoch [900/1000], Loss: 0.0010\n",
            "Epoch [1000/1000], Loss: 0.0004\n",
            "final loss: 0.0004\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y9tl-y5f2zRp"
      },
      "source": [
        "\n",
        "##\tSaving the Trained Model\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TIQP3GpfPOm2",
        "outputId": "7189f77f-e7c0-4d22-d645-7be9d255856b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 32
        }
      },
      "source": [
        "\n",
        "FILE = \"data.pth\"\n",
        "torch.save(data, FILE)\n",
        "\n",
        "print(f'training complete. file saved to {FILE}')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "training complete. file saved to data.pth\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IH52MJobTFEU"
      },
      "source": [
        "\n",
        "## Loading our Saved Model\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FX0f_8TgPRqK",
        "outputId": "865b4c48-c7d0-4d04-fa33-c733eb817081",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 115
        }
      },
      "source": [
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "with open('intents.json', 'r') as json_data:\n",
        "    intents = json.load(json_data)\n",
        "\n",
        "FILE = \"data.pth\"\n",
        "data = torch.load(FILE)\n",
        "\n",
        "input_size = data[\"input_size\"]\n",
        "hidden_size = data[\"hidden_size\"]\n",
        "output_size = data[\"output_size\"]\n",
        "all_words = data['all_words']\n",
        "tags = data['tags']\n",
        "model_state = data[\"model_state\"]\n",
        "\n",
        "model = NeuralNet(input_size, hidden_size, output_size).to(device)\n",
        "model.load_state_dict(model_state)\n",
        "model.eval()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "NeuralNet(\n",
              "  (l1): Linear(in_features=54, out_features=8, bias=True)\n",
              "  (l2): Linear(in_features=8, out_features=8, bias=True)\n",
              "  (l3): Linear(in_features=8, out_features=7, bias=True)\n",
              "  (relu): ReLU()\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dLOf1gRd2-YH"
      },
      "source": [
        "\n",
        " \n",
        "## Using the Chatbot:\n",
        "---\n",
        "Our Model is Ready. Now we will finally chat with our chat-bot. As our training data was very limited, we can only chat about a handful of topics. You can train it on a bigger dataset to increase the chatbot’s generalization / knowledge."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U_tGgw41THXL",
        "outputId": "2574256f-d833-4944-e3c5-6354c0c0bea0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 543
        }
      },
      "source": [
        "\n",
        "bot_name = \"Sam\"\n",
        "print(\"Let's chat! (type 'quit' to exit)\")\n",
        "while True:\n",
        "    # sentence = \"do you use credit cards?\"\n",
        "    sentence = input(\"You: \")\n",
        "    if sentence == \"quit\":\n",
        "        break\n",
        "\n",
        "    sentence = tokenize(sentence)\n",
        "    X = bag_of_words(sentence, all_words)\n",
        "    X = X.reshape(1, X.shape[0])\n",
        "    X = torch.from_numpy(X).to(device)\n",
        "\n",
        "    output = model(X)\n",
        "    _, predicted = torch.max(output, dim=1)\n",
        "\n",
        "    tag = tags[predicted.item()]\n",
        "\n",
        "    probs = torch.softmax(output, dim=1)\n",
        "    prob = probs[0][predicted.item()]\n",
        "    if prob.item() > 0.75:\n",
        "        for intent in intents['intents']:\n",
        "            if tag == intent[\"tag\"]:\n",
        "                print(f\"{bot_name}: {random.choice(intent['responses'])}\")\n",
        "    else:\n",
        "        print(f\"{bot_name}: I do not understand...\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Let's chat! (type 'quit' to exit)\n",
            "You: hey\n",
            "Sam: Hi there, what can I do for you?\n",
            "You: do you have money?\n",
            "Sam: We have coffee and tea\n",
            "You: i only have cash\n",
            "Sam: We accept VISA, Mastercard and Paypal\n",
            "You: i have visa\n",
            "Sam: I do not understand...\n",
            "You: what is your name?\n",
            "Sam: Hello, thanks for visiting\n",
            "You: bye\n",
            "Sam: Have a nice day\n",
            "You: thanks\n",
            "Sam: My pleasure\n",
            "You: good morning\n",
            "Sam: Hello, thanks for visiting\n",
            "You: do you deliver?\n",
            "Sam: I do not understand...\n",
            "You: when do i get my order?\n",
            "Sam: Delivery takes 2-4 days\n",
            "You: i want coffee\n",
            "Sam: I do not understand...\n",
            "You: tell me a joke\n",
            "Sam: What did the buffalo say when his son left for college? Bison.\n",
            "You: another one\n",
            "Sam: I do not understand...\n",
            "You: tell me a joke\n",
            "Sam: What did the buffalo say when his son left for college? Bison.\n",
            "You: joke\n",
            "Sam: I do not understand...\n",
            "You: quit\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BE7D2Ma03GMo"
      },
      "source": [
        "\n",
        "`Our Model has been trained with very few examples, so it does not understand everything. It is a great start for new learners. Just train this exact model on a bigger dataset & Voila, You'll see the charm .`\n",
        "\n",
        " \n",
        "\n",
        "\n",
        "\n",
        "# Bibliography\n",
        "---\n",
        "\n",
        "\n",
        "**[1]** \tWikipedia, \"FeedForward Neural Network,\" Wikipedia, [Online]. Available: https://en.wikipedia.org/wiki/Feedforward_neural_network.\n",
        "\n",
        "**[2]** \tT. Wood, \"Activation Function,\" DeepAI, [Online]. Available: https://deepai.org/machine-learning-glossary-and-terms/activation-function.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Coy7b5xSTMLy"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}